{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 - Deep MLP\n",
        "Train the Deep MLP and visualize results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "ROOT = Path(\"..\").resolve()\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.append(str(ROOT))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from src.models import make_mlp_model, make_pipeline, build_search\nfrom src.eval import evaluate_models\nfrom src.plots import plot_actual_vs_pred, plot_error_distribution\nfrom _common import load_dataset, prepare_features\nfrom src.split import SplitConfig\n\nSEED = 42\nTUNE_MODE = \"fast\"  # off | fast | full\nMLP_VERBOSE = 2  # 0/False, 1=tqdm, 2=tqdm + per-epoch log\nMLP_LOG_EVERY = 1\nMLP_BATCH_LOG_EVERY = 50  # set 0 to disable\nMLP_LIVE_PLOT_EVERY = 5   # epochs; set 0 to disable\nsplit_config = SplitConfig(test_rounds=6)\ndf, metadata = load_dataset()\ntrain_df, val_df, trainval_df, test_df, features = prepare_features(df, metadata, split_config=split_config)\n\nX_train = train_df[features]\ny_train = train_df[\"LapTimeSeconds\"].to_numpy()\nX_val = val_df[features]\ny_val = val_df[\"LapTimeSeconds\"].to_numpy()\n\nbase = make_pipeline(make_mlp_model(SEED, verbose=MLP_VERBOSE, log_every=MLP_LOG_EVERY, log_batch_every=MLP_BATCH_LOG_EVERY, live_plot_every=MLP_LIVE_PLOT_EVERY), features)\nmodel = build_search(\"Deep MLP\", base, random_state=SEED, mode=TUNE_MODE)\nmetrics, preds, fitted = evaluate_models({\"Deep MLP\": model}, X_train, y_train, X_val, y_val)\nmetrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "best = fitted[\"Deep MLP\"].best_estimator_ if hasattr(fitted[\"Deep MLP\"], \"best_estimator_\") else fitted[\"Deep MLP\"]\n",
        "X_trainval = trainval_df[features]\n",
        "y_trainval = trainval_df[\"LapTimeSeconds\"].to_numpy()\n",
        "X_test = test_df[features]\n",
        "y_test = test_df[\"LapTimeSeconds\"].to_numpy()\n",
        "best.fit(X_trainval, y_trainval)\n",
        "test_pred = best.predict(X_test)\n",
        "\n",
        "plot_actual_vs_pred(y_test, test_pred, title=\"Deep MLP: Predicted vs Actual\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_error_distribution(y_test, test_pred, title=\"Deep MLP: Residuals\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training history (post-hoc)\n",
        "import plotly.express as px\n",
        "\n",
        "est = fitted[\"Deep MLP\"]\n",
        "if hasattr(est, \"best_estimator_\"):\n",
        "    est = est.best_estimator_\n",
        "model = est.named_steps[\"model\"]\n",
        "hist = getattr(model, \"training_history_\", None)\n",
        "if hist:\n",
        "    df_hist = pd.DataFrame(hist)\n",
        "    fig = px.line(df_hist, y=[\"train_loss\", \"val_loss\"], title=\"Deep MLP Training Curves\")\n",
        "    fig\n",
        "else:\n",
        "    print(\"No training history found.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}