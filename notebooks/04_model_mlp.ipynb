{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Deep MLP\n",
    "Train the Deep MLP and visualize results.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "ROOT = Path(\"..\").resolve()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import importlib\n",
    "import src.models as models\n",
    "importlib.reload(models)\n",
    "make_mlp_model = models.make_mlp_model\n",
    "make_pipeline = models.make_pipeline\n",
    "build_search = models.build_search\n",
    "from src.eval import evaluate_models\n",
    "from src.plots import plot_actual_vs_pred, plot_error_distribution\n",
    "from _common import load_dataset, prepare_features\n",
    "from src.split import SplitConfig\n",
    "from contextlib import contextmanager\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "SMALL_MODE = True  # toggle for quick iteration\n",
    "TUNE_MODE = \"fast\"  # off | fast | full\n",
    "SEARCH_VERBOSE = 2  # sklearn CV logging\n",
    "SEARCH_N_ITER = None  # only used for randomized search\n",
    "SHOW_CV_TQDM = True  # tqdm progress for CV fits\n",
    "\n",
    "MLP_VERBOSE = 2  # 0/False, 1=tqdm, 2=tqdm + per-epoch log\n",
    "MLP_LOG_EVERY = 1\n",
    "MLP_BATCH_LOG_EVERY = 20  # set 0 to disable\n",
    "MLP_LIVE_PLOT_EVERY = 5   # epochs; set 0 to disable\n",
    "\n",
    "# Small-mode overrides\n",
    "MLP_HIDDEN_LAYERS = None\n",
    "MLP_EPOCHS = None\n",
    "MLP_BATCH_SIZE = None\n",
    "MLP_PARAM_GRID = None\n",
    "if SMALL_MODE:\n",
    "    MLP_HIDDEN_LAYERS = (128, 64)\n",
    "    MLP_EPOCHS = 40\n",
    "    MLP_BATCH_SIZE = 64\n",
    "    SEARCH_N_ITER = 6\n",
    "    MLP_PARAM_GRID = {\n",
    "        \"model__hidden_layers\": [(128, 64), (128, 64, 32)],\n",
    "        \"model__dropout\": [0.2, 0.3],\n",
    "        \"model__lr\": [1e-3],\n",
    "        \"model__batch_size\": [64, 128],\n",
    "        \"model__epochs\": [30, 60],\n",
    "        \"model__weight_decay\": [0.0, 1e-4],\n",
    "    }\n",
    "\n",
    "# Optional GPU info + explicit device\n",
    "DEVICE = None\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        DEVICE = \"cuda\"\n",
    "        print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        DEVICE = \"cpu\"\n",
    "        print(\"GPU not available; using CPU.\")\n",
    "except Exception as exc:\n",
    "    print(f\"Torch not available for GPU check ({exc}).\")\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def tqdm_joblib(total, desc=\"CV fits\"):\n",
    "    try:\n",
    "        import joblib\n",
    "        from tqdm.auto import tqdm\n",
    "    except Exception:  # noqa: BLE001\n",
    "        yield None\n",
    "        return\n",
    "\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            try:\n",
    "                tqdm_bar.update(n=self.batch_size)\n",
    "            except Exception:\n",
    "                pass\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    tqdm_bar = tqdm(total=total, desc=desc)\n",
    "    old_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_bar\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_callback\n",
    "        tqdm_bar.close()\n",
    "\n",
    "\n",
    "def estimate_total_fits(search):\n",
    "    try:\n",
    "        n_splits = search.cv.get_n_splits()\n",
    "    except Exception:\n",
    "        n_splits = getattr(search.cv, \"n_splits\", 1)\n",
    "    if hasattr(search, \"n_iter\"):\n",
    "        n_candidates = search.n_iter\n",
    "    else:\n",
    "        try:\n",
    "            from sklearn.model_selection import ParameterGrid\n",
    "            n_candidates = len(list(ParameterGrid(search.param_grid)))\n",
    "        except Exception:\n",
    "            n_candidates = 1\n",
    "    return n_splits * n_candidates\n",
    "\n",
    "\n",
    "split_config = SplitConfig(test_rounds=6)\n",
    "df, metadata = load_dataset()\n",
    "train_df, val_df, trainval_df, test_df, features = prepare_features(df, metadata, split_config=split_config)\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[\"LapTimeSeconds\"].to_numpy()\n",
    "X_val = val_df[features]\n",
    "y_val = val_df[\"LapTimeSeconds\"].to_numpy()\n",
    "\n",
    "base = make_pipeline(\n",
    "    make_mlp_model(\n",
    "        SEED,\n",
    "        verbose=MLP_VERBOSE,\n",
    "        log_every=MLP_LOG_EVERY,\n",
    "        log_batch_every=MLP_BATCH_LOG_EVERY,\n",
    "        live_plot_every=MLP_LIVE_PLOT_EVERY,\n",
    "        hidden_layers=MLP_HIDDEN_LAYERS,\n",
    "        epochs=MLP_EPOCHS,\n",
    "        batch_size=MLP_BATCH_SIZE,\n",
    "        device=DEVICE,\n",
    "    ),\n",
    "    features,\n",
    ")\n",
    "model = build_search(\n",
    "    \"Deep MLP\",\n",
    "    base,\n",
    "    random_state=SEED,\n",
    "    mode=TUNE_MODE,\n",
    "    param_grid=MLP_PARAM_GRID,\n",
    "    n_iter=SEARCH_N_ITER,\n",
    "    search_verbose=SEARCH_VERBOSE,\n",
    ")\n",
    "\n",
    "if SHOW_CV_TQDM and hasattr(model, \"cv\"):\n",
    "    total_fits = estimate_total_fits(model)\n",
    "    with tqdm_joblib(total_fits, desc=\"CV fits\"):\n",
    "        metrics, preds, fitted = evaluate_models({\"Deep MLP\": model}, X_train, y_train, X_val, y_val)\n",
    "else:\n",
    "    metrics, preds, fitted = evaluate_models({\"Deep MLP\": model}, X_train, y_train, X_val, y_val)\n",
    "\n",
    "metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "best = fitted[\"Deep MLP\"].best_estimator_ if hasattr(fitted[\"Deep MLP\"], \"best_estimator_\") else fitted[\"Deep MLP\"]\n",
    "X_trainval = trainval_df[features]\n",
    "y_trainval = trainval_df[\"LapTimeSeconds\"].to_numpy()\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[\"LapTimeSeconds\"].to_numpy()\n",
    "best.fit(X_trainval, y_trainval)\n",
    "test_pred = best.predict(X_test)\n",
    "\n",
    "plot_actual_vs_pred(y_test, test_pred, title=\"Deep MLP: Predicted vs Actual\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_error_distribution(y_test, test_pred, title=\"Deep MLP: Residuals\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Training history (post-hoc)\n",
    "import plotly.express as px\n",
    "\n",
    "est = fitted[\"Deep MLP\"]\n",
    "if hasattr(est, \"best_estimator_\"):\n",
    "    est = est.best_estimator_\n",
    "model = est.named_steps[\"model\"]\n",
    "hist = getattr(model, \"training_history_\", None)\n",
    "if hist:\n",
    "    df_hist = pd.DataFrame(hist)\n",
    "    fig = px.line(df_hist, y=[\"train_loss\", \"val_loss\"], title=\"Deep MLP Training Curves\")\n",
    "    fig\n",
    "else:\n",
    "    print(\"No training history found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}