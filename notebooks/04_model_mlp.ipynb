{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 - Deep MLP\n",
        "Train the Deep MLP and visualize results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "ROOT = Path(\"..\").resolve()\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.append(str(ROOT))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import importlib\n",
        "from pathlib import Path\n",
        "\n",
        "import src.models as models\n",
        "importlib.reload(models)\n",
        "make_mlp_model = models.make_mlp_model\n",
        "make_pipeline = models.make_pipeline\n",
        "build_search = models.build_search\n",
        "from src.eval import evaluate_models\n",
        "from src.plots import plot_actual_vs_pred, plot_error_distribution\n",
        "from _common import load_dataset, prepare_features, ROOT\n",
        "from src.split import SplitConfig\n",
        "from contextlib import contextmanager\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "SMALL_MODE = True  # toggle for quick iteration\n",
        "TUNE_MODE = \"fast\"  # off | fast | full\n",
        "SEARCH_VERBOSE = 2  # sklearn CV logging\n",
        "SEARCH_N_ITER = None  # only used for randomized search\n",
        "SHOW_CV_TQDM = True  # tqdm progress for CV fits\n",
        "\n",
        "# MLflow\n",
        "MLFLOW_ENABLED = True\n",
        "MLFLOW_EXPERIMENT = \"f1-laptime\"\n",
        "MLFLOW_TRACKING_URI = (ROOT / \"mlruns\").as_uri()\n",
        "MLFLOW_RUN_NAME = \"mlp_notebook\"\n",
        "\n",
        "# Verify MLflow availability\n",
        "if MLFLOW_ENABLED:\n",
        "    try:\n",
        "        import mlflow  # noqa: F401\n",
        "        print(f\"MLflow available: {mlflow.__version__}\")\n",
        "    except Exception:\n",
        "        print(\"MLflow not installed; set MLFLOW_ENABLED=False or install mlflow.\")\n",
        "        MLFLOW_ENABLED = False\n",
        "\n",
        "# Model saving\n",
        "SAVE_MODEL = True\n",
        "MODEL_PATH = ROOT / \"reports\" / \"models\" / \"deep_mlp.joblib\"\n",
        "\n",
        "MLP_VERBOSE = 2  # 0/False, 1=tqdm, 2=tqdm + per-epoch log\n",
        "MLP_LOG_EVERY = 1\n",
        "MLP_BATCH_LOG_EVERY = 20  # set 0 to disable\n",
        "MLP_LIVE_PLOT_EVERY = 5   # epochs; set 0 to disable\n",
        "\n",
        "# Small-mode overrides / base hyperparameters\n",
        "MLP_HIDDEN_LAYERS = None\n",
        "MLP_EPOCHS = None\n",
        "MLP_BATCH_SIZE = None\n",
        "MLP_DROPOUT = None\n",
        "MLP_LR = None\n",
        "MLP_WEIGHT_DECAY = None\n",
        "MLP_PARAM_GRID = None\n",
        "if SMALL_MODE:\n",
        "    MLP_HIDDEN_LAYERS = (128, 64)\n",
        "    MLP_EPOCHS = 40\n",
        "    MLP_BATCH_SIZE = 64\n",
        "    SEARCH_N_ITER = 6\n",
        "    MLP_PARAM_GRID = {\n",
        "        \"model__hidden_layers\": [(128, 64), (128, 64, 32)],\n",
        "        \"model__dropout\": [0.2, 0.3],\n",
        "        \"model__lr\": [1e-3],\n",
        "        \"model__batch_size\": [64, 128],\n",
        "        \"model__epochs\": [30, 60],\n",
        "        \"model__weight_decay\": [0.0, 1e-4],\n",
        "    }\n",
        "\n",
        "# Optional GPU info + explicit device\n",
        "DEVICE = None\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        DEVICE = \"cuda\"\n",
        "        print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        DEVICE = \"cpu\"\n",
        "        print(\"GPU not available; using CPU.\")\n",
        "except Exception as exc:\n",
        "    print(f\"Torch not available for GPU check ({exc}).\")\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def tqdm_joblib(total, desc=\"CV fits\"):\n",
        "    try:\n",
        "        import joblib\n",
        "        from tqdm.auto import tqdm\n",
        "    except Exception:  # noqa: BLE001\n",
        "        yield None\n",
        "        return\n",
        "\n",
        "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
        "        def __call__(self, *args, **kwargs):\n",
        "            try:\n",
        "                tqdm_bar.update(n=self.batch_size)\n",
        "            except Exception:\n",
        "                pass\n",
        "            return super().__call__(*args, **kwargs)\n",
        "\n",
        "    tqdm_bar = tqdm(total=total, desc=desc)\n",
        "    old_callback = joblib.parallel.BatchCompletionCallBack\n",
        "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
        "    try:\n",
        "        yield tqdm_bar\n",
        "    finally:\n",
        "        joblib.parallel.BatchCompletionCallBack = old_callback\n",
        "        tqdm_bar.close()\n",
        "\n",
        "\n",
        "def estimate_total_fits(search):\n",
        "    try:\n",
        "        n_splits = search.cv.get_n_splits()\n",
        "    except Exception:\n",
        "        n_splits = getattr(search.cv, \"n_splits\", 1)\n",
        "    if hasattr(search, \"n_iter\"):\n",
        "        n_candidates = search.n_iter\n",
        "    else:\n",
        "        try:\n",
        "            from sklearn.model_selection import ParameterGrid\n",
        "            n_candidates = len(list(ParameterGrid(search.param_grid)))\n",
        "        except Exception:\n",
        "            n_candidates = 1\n",
        "    return n_splits * n_candidates\n",
        "\n",
        "\n",
        "split_config = SplitConfig(test_rounds=6)\n",
        "df, metadata = load_dataset()\n",
        "train_df, val_df, trainval_df, test_df, features = prepare_features(df, metadata, split_config=split_config)\n",
        "\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[\"LapTimeSeconds\"].to_numpy()\n",
        "X_val = val_df[features]\n",
        "y_val = val_df[\"LapTimeSeconds\"].to_numpy()\n",
        "\n",
        "base = make_pipeline(\n",
        "    make_mlp_model(\n",
        "        SEED,\n",
        "        verbose=MLP_VERBOSE,\n",
        "        log_every=MLP_LOG_EVERY,\n",
        "        log_batch_every=MLP_BATCH_LOG_EVERY,\n",
        "        live_plot_every=MLP_LIVE_PLOT_EVERY,\n",
        "        hidden_layers=MLP_HIDDEN_LAYERS,\n",
        "        epochs=MLP_EPOCHS,\n",
        "        batch_size=MLP_BATCH_SIZE,\n",
        "        dropout=MLP_DROPOUT,\n",
        "        lr=MLP_LR,\n",
        "        weight_decay=MLP_WEIGHT_DECAY,\n",
        "        device=DEVICE,\n",
        "    ),\n",
        "    features,\n",
        ")\n",
        "model = build_search(\n",
        "    \"Deep MLP\",\n",
        "    base,\n",
        "    random_state=SEED,\n",
        "    mode=TUNE_MODE,\n",
        "    param_grid=MLP_PARAM_GRID,\n",
        "    n_iter=SEARCH_N_ITER,\n",
        "    search_verbose=SEARCH_VERBOSE,\n",
        ")\n",
        "\n",
        "if SHOW_CV_TQDM and hasattr(model, \"cv\"):\n",
        "    total_fits = estimate_total_fits(model)\n",
        "    with tqdm_joblib(total_fits, desc=\"CV fits\"):\n",
        "        metrics, preds, fitted = evaluate_models({\"Deep MLP\": model}, X_train, y_train, X_val, y_val)\n",
        "else:\n",
        "    metrics, preds, fitted = evaluate_models({\"Deep MLP\": model}, X_train, y_train, X_val, y_val)\n",
        "\n",
        "metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "best = fitted[\"Deep MLP\"].best_estimator_ if hasattr(fitted[\"Deep MLP\"], \"best_estimator_\") else fitted[\"Deep MLP\"]\n",
        "X_trainval = trainval_df[features]\n",
        "y_trainval = trainval_df[\"LapTimeSeconds\"].to_numpy()\n",
        "X_test = test_df[features]\n",
        "y_test = test_df[\"LapTimeSeconds\"].to_numpy()\n",
        "best.fit(X_trainval, y_trainval)\n",
        "test_pred = best.predict(X_test)\n",
        "\n",
        "plot_actual_vs_pred(y_test, test_pred, title=\"Deep MLP: Predicted vs Actual\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_error_distribution(y_test, test_pred, title=\"Deep MLP: Residuals\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training history (post-hoc)\n",
        "import plotly.express as px\n",
        "\n",
        "est = fitted[\"Deep MLP\"]\n",
        "if hasattr(est, \"best_estimator_\"):\n",
        "    est = est.best_estimator_\n",
        "model = est.named_steps[\"model\"]\n",
        "hist = getattr(model, \"training_history_\", None)\n",
        "if hist:\n",
        "    df_hist = pd.DataFrame(hist)\n",
        "    fig = px.line(df_hist, y=[\"train_loss\", \"val_loss\"], title=\"Deep MLP Training Curves\")\n",
        "    fig\n",
        "else:\n",
        "    print(\"No training history found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from src.eval import compute_metrics\n",
        "import joblib\n",
        "\n",
        "# Test metrics\n",
        "mlp_test_metrics = compute_metrics(y_test, test_pred)\n",
        "mlp_test_metrics\n",
        "\n",
        "# Save model for inference\n",
        "if SAVE_MODEL:\n",
        "    MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "    joblib.dump(best, MODEL_PATH)\n",
        "    print(f\"Saved model to {MODEL_PATH}\")\n",
        "\n",
        "# MLflow logging\n",
        "if MLFLOW_ENABLED:\n",
        "    try:\n",
        "        import mlflow\n",
        "    except ImportError:\n",
        "        print(\"MLflow not installed; skipping MLflow logging.\")\n",
        "    else:\n",
        "        def _coerce_params(params):\n",
        "            return {k: str(v) for k, v in params.items()}\n",
        "\n",
        "        if MLFLOW_TRACKING_URI:\n",
        "            mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "        mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
        "        with mlflow.start_run(run_name=MLFLOW_RUN_NAME or \"mlp_notebook\"):\n",
        "            mlflow.log_param(\"tune_mode\", TUNE_MODE)\n",
        "            mlflow.log_param(\"small_mode\", SMALL_MODE)\n",
        "            mlflow.log_param(\"test_rounds\", split_config.test_rounds)\n",
        "\n",
        "            if hasattr(fitted[\"Deep MLP\"], \"best_params_\"):\n",
        "                mlflow.log_params(_coerce_params(fitted[\"Deep MLP\"].best_params_))\n",
        "            else:\n",
        "                base_params = {\n",
        "                    \"hidden_layers\": MLP_HIDDEN_LAYERS,\n",
        "                    \"dropout\": MLP_DROPOUT,\n",
        "                    \"lr\": MLP_LR,\n",
        "                    \"epochs\": MLP_EPOCHS,\n",
        "                    \"batch_size\": MLP_BATCH_SIZE,\n",
        "                    \"weight_decay\": MLP_WEIGHT_DECAY,\n",
        "                }\n",
        "                mlflow.log_params(_coerce_params({k: v for k, v in base_params.items() if v is not None}))\n",
        "\n",
        "            row = metrics[metrics[\"model\"] == \"Deep MLP\"].iloc[0]\n",
        "            for metric in (\"mae\", \"rmse\", \"r2\"):\n",
        "                mlflow.log_metric(f\"val_{metric}\", float(row[metric]))\n",
        "            for metric in (\"mae\", \"rmse\", \"r2\"):\n",
        "                mlflow.log_metric(f\"test_{metric}\", float(mlp_test_metrics[metric]))\n",
        "\n",
        "            if SAVE_MODEL and MODEL_PATH.exists():\n",
        "                mlflow.log_artifact(str(MODEL_PATH), artifact_path=\"models\")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}