{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Linear Model\n",
    "Train a linear baseline and visualize results.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "ROOT = Path(\"..\").resolve()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from src.models import make_linear_model, make_pipeline, build_search\n",
    "from src.eval import evaluate_models, compute_full_metrics\n",
    "from src.plots import plot_actual_vs_pred, plot_error_distribution, plot_model_comparison\n",
    "from _common import load_dataset, prepare_features, ROOT\n",
    "from src.split import SplitConfig\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "SMALL_MODE = True  # toggle for quick iteration\n",
    "TUNE_MODE = \"off\"  # off | fast | full\n",
    "SEARCH_VERBOSE = 2  # sklearn CV logging\n",
    "SEARCH_N_ITER = None  # only used for randomized search\n",
    "\n",
    "# MLflow\n",
    "MLFLOW_ENABLED = True\n",
    "MLFLOW_EXPERIMENT = \"f1-laptime\"\n",
    "MLFLOW_TRACKING_URI = (ROOT / \"mlruns\").as_uri()\n",
    "MLFLOW_RUN_NAME = \"linear_notebook\"\n",
    "\n",
    "# Verify MLflow availability\n",
    "if MLFLOW_ENABLED:\n",
    "    try:\n",
    "        import mlflow  # noqa: F401\n",
    "        print(f\"MLflow available: {mlflow.__version__}\")\n",
    "    except Exception:\n",
    "        print(\"MLflow not installed; set MLFLOW_ENABLED=False or install mlflow.\")\n",
    "        MLFLOW_ENABLED = False\n",
    "\n",
    "# Model saving\n",
    "SAVE_MODEL = True\n",
    "MODEL_PATH = ROOT / \"reports\" / \"models\" / \"linear.joblib\"\n",
    "\n",
    "# Base params (used even when tuning is off)\n",
    "LINEAR_ALPHA = None\n",
    "\n",
    "# Tuning grid (used when tuning is on)\n",
    "LINEAR_PARAM_GRID = None\n",
    "if SMALL_MODE:\n",
    "    LINEAR_ALPHA = 1.0\n",
    "    SEARCH_N_ITER = 6\n",
    "    LINEAR_PARAM_GRID = {\"model__alpha\": [0.1, 0.5, 1.0, 5.0]}\n",
    "\n",
    "split_config = SplitConfig(test_rounds=None)\n",
    "df, metadata = load_dataset()\n",
    "train_df, val_df, trainval_df, test_df, features = prepare_features(df, metadata, split_config=split_config)\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[\"LapTimeSeconds\"].to_numpy()\n",
    "X_val = val_df[features]\n",
    "y_val = val_df[\"LapTimeSeconds\"].to_numpy()\n",
    "\n",
    "base = make_pipeline(make_linear_model(SEED, alpha=LINEAR_ALPHA), features)\n",
    "model = build_search(\n",
    "    \"Linear\",\n",
    "    base,\n",
    "    random_state=SEED,\n",
    "    mode=TUNE_MODE,\n",
    "    param_grid=LINEAR_PARAM_GRID,\n",
    "    n_iter=SEARCH_N_ITER,\n",
    "    search_verbose=SEARCH_VERBOSE,\n",
    ")\n",
    "metrics, preds, fitted = evaluate_models({\"Linear\": model}, X_train, y_train, X_val, y_val)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "best = fitted[\"Linear\"]\n",
    "X_trainval = trainval_df[features]\n",
    "y_trainval = trainval_df[\"LapTimeSeconds\"].to_numpy()\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[\"LapTimeSeconds\"].to_numpy()\n",
    "best.fit(X_trainval, y_trainval)\n",
    "test_pred = best.predict(X_test)\n",
    "\n",
    "plot_actual_vs_pred(y_test, test_pred, title=\"Linear: Predicted vs Actual\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_error_distribution(y_test, test_pred, title=\"Linear: Residuals\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import joblib\n",
    "\n",
    "# Test metrics (full 2025 season)\n",
    "linear_test_metrics = compute_full_metrics(y_test, test_pred, n_features=len(features))\n",
    "linear_test_metrics\n",
    "\n",
    "# Save model for inference\n",
    "if SAVE_MODEL:\n",
    "    MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(best, MODEL_PATH)\n",
    "    print(\"Saved model to {}\".format(MODEL_PATH))\n",
    "\n",
    "# MLflow logging\n",
    "if MLFLOW_ENABLED:\n",
    "    try:\n",
    "        import mlflow\n",
    "    except ImportError:\n",
    "        print(\"MLflow not installed; skipping MLflow logging.\")\n",
    "    else:\n",
    "        def _coerce_params(params):\n",
    "            return {k: str(v) for k, v in params.items()}\n",
    "\n",
    "        if MLFLOW_TRACKING_URI:\n",
    "            mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "        mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
    "        with mlflow.start_run(run_name=MLFLOW_RUN_NAME or \"linear_notebook\"):\n",
    "            mlflow.log_param(\"tune_mode\", TUNE_MODE)\n",
    "            mlflow.log_param(\"small_mode\", SMALL_MODE)\n",
    "            mlflow.log_param(\"test_rounds\", split_config.test_rounds)\n",
    "\n",
    "            if hasattr(fitted[\"Linear\"], \"best_params_\"):\n",
    "                mlflow.log_params(_coerce_params(fitted[\"Linear\"].best_params_))\n",
    "            elif LINEAR_ALPHA is not None:\n",
    "                mlflow.log_param(\"alpha\", LINEAR_ALPHA)\n",
    "\n",
    "            row = metrics[metrics[\"model\"] == \"Linear\"].iloc[0]\n",
    "            for metric in (\"mae\", \"rmse\", \"r2\"):\n",
    "                mlflow.log_metric(\"val_\" + metric, float(row[metric]))\n",
    "            for metric in (\"mae\", \"rmse\", \"r2\", \"mape_pct\", \"smape_pct\"):\n",
    "                if metric in linear_test_metrics:\n",
    "                    mlflow.log_metric(\"test_\" + metric, float(linear_test_metrics[metric]))\n",
    "\n",
    "            if SAVE_MODEL and MODEL_PATH.exists():\n",
    "                mlflow.log_artifact(str(MODEL_PATH), artifact_path=\"models\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}